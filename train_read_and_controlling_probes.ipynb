{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a470bf-9778-4f42-9e02-75bf5b56da77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from losses import edl_mse_loss\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from dataset import TextDataset \n",
    "from losses import edl_mse_loss\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "from probes import ProbeClassification, ProbeClassificationMixScaler\n",
    "from train_test_utils import train, test \n",
    "import torch.nn as nn\n",
    "\n",
    "import time\n",
    "\n",
    "tic, toc = (time.time, time.time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593bc99d-913a-4b4a-adef-5fed5a374cd5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-2-13b-chat-hf\", use_auth_token=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Llama-2-13b-chat-hf\", use_auth_token=True)\n",
    "model.half().cuda();\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9890f7cf-4cca-4046-a323-b617d87d98f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.probes import ProbeClassification, ProbeClassificationMixScaler\n",
    "    \n",
    "class TrainerConfig:\n",
    "    # optimization parameters\n",
    "    max_epochs = 10\n",
    "    batch_size = 64\n",
    "    learning_rate = 1e-3\n",
    "    betas = (0.9, 0.95)\n",
    "    grad_norm_clip = 1.0\n",
    "    weight_decay = 0.1 # only applied on matmul weights\n",
    "    # learning rate decay params: linear warmup followed by cosine decay to 10% of original\n",
    "    lr_decay = False\n",
    "    # checkpoint settings\n",
    "    ckpt_path = None\n",
    "    num_workers = 0 # for DataLoader\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        for k,v in kwargs.items():\n",
    "            setattr(self, k, v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e307edd-b217-42f6-b4a0-895fc72cb69f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Linear Probing on All Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433ab263-869f-4a26-a01b-85f99557b927",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "from src.dataset import split_conversation, llama_v2_prompt, TextDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d908228-1295-4a70-9d3e-7ef1fddef37a",
   "metadata": {},
   "source": [
    "### Reading Probes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c933a6f-7d4b-4f65-b42f-a464dd300365",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from probes import LinearProbeClassification, LinearProbeClassificationMixScaler\n",
    "import sklearn.model_selection\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "jump_socioeco = True\n",
    "\n",
    "new_prompt_format=True\n",
    "residual_stream=True\n",
    "uncertainty = False\n",
    "logistic = True\n",
    "augmented = False\n",
    "remove_last_ai_response = True\n",
    "include_inst = True\n",
    "one_hot = True\n",
    "\n",
    "label_to_id_age = {\"child\": 0,\n",
    "                   \"adolescent\": 1,\n",
    "                   \"adult\": 2,\n",
    "                   \"older adult\": 3,\n",
    "                  }\n",
    "\n",
    "label_to_id_gender = {\"male\": 0,\n",
    "                      \"female\": 1,\n",
    "                     }\n",
    "\n",
    "label_to_id_socioeconomic = {\"low\": 0,\n",
    "                             \"middle\": 1,\n",
    "                             \"high\": 2}\n",
    "\n",
    "label_to_id_neweducation = {\"someschool\": 0,\n",
    "                            \"highschool\": 1,\n",
    "                            \"collegemore\": 2}\n",
    "\n",
    "prompt_translator = {\"_age_\": \"age\",\n",
    "                     \"_gender_\": \"gender\",\n",
    "                     \"_socioeco_\": \"socioeconomic status\",\n",
    "                     \"_education_\": \"education level\",}\n",
    "\n",
    "openai_dataset = {\"_age_\": \"dataset/openai_age_1/\",\n",
    "                  \"_gender_\": \"dataset/openai_gender_1/\",\n",
    "                  \"_education_\": \"dataset/openai_education_1/\",\n",
    "                  \"_socioeco_\": \"dataset/openai_socioeconomic_1/\",}\n",
    "\n",
    "accuracy_dict = {}\n",
    "\n",
    "directories = [\"dataset/llama_age_1/\", \"dataset/llama_gender_1/\",\n",
    "               \"dataset/llama_socioeconomic_1/\", \"dataset/openai_education_1/\"]\n",
    "\n",
    "label_idfs = [\"_age_\", \"_gender_\", \"_socioeco_\", \"_education_\"]\n",
    "\n",
    "label_to_ids = [label_to_id_age, label_to_id_gender,\n",
    "                label_to_id_socioeconomic, label_to_id_neweducation]\n",
    "\n",
    "for directory, label_idf, label_to_id in zip(directories, label_idfs, label_to_ids):\n",
    "    # additional_dataset=[directory[:-1] + \"_additional/\"]\n",
    "    if label_idf == \"_education_\":\n",
    "        additional_dataset=[]\n",
    "    else:\n",
    "        additional_dataset=[directory[:-2] + \"_2/\", openai_dataset[label_idf]]\n",
    "    if label_idf == \"_gender_\":\n",
    "        additional_dataset += [\"dataset/openai_gender_2/\", \"dataset/openai_gender_3/\", \n",
    "                               \"dataset/openai_gender_4\",]\n",
    "    if label_idf == \"_education_\":\n",
    "        additional_dataset += [\"dataset/openai_education_2\", \"dataset/openai_education_3/\"]\n",
    "    if label_idf == \"_socioeco_\":\n",
    "        additional_dataset += [\"dataset/openai_socioeconomic_2/\", \"dataset/openai_socioeconomic_3/\"]\n",
    "    if label_idf == \"_age_\":\n",
    "        additional_dataset += [\"dataset/openai_age_2/\", \"dataset/openai_age_3/\"]\n",
    "        \n",
    "    dataset = TextDataset(directory, tokenizer, model, label_idf=label_idf, label_to_id=label_to_id,\n",
    "                          convert_to_llama2_format=True, additional_datas=additional_dataset, \n",
    "                          new_format=new_prompt_format,\n",
    "                          residual_stream=residual_stream, if_augmented=augmented, \n",
    "                          remove_last_ai_response=remove_last_ai_response, include_inst=include_inst, k=1,\n",
    "                          one_hot=False, last_tok_pos=-1)\n",
    "    dict_name = label_idf.strip(\"_\")\n",
    "\n",
    "    train_size = int(0.8 * len(dataset))\n",
    "    test_size = len(dataset) - train_size\n",
    "    train_idx, val_idx = sklearn.model_selection.train_test_split(list(range(len(dataset))), \n",
    "                                                                  test_size=test_size,\n",
    "                                                                  train_size=train_size,\n",
    "                                                                  random_state=12345,\n",
    "                                                                  shuffle=True,\n",
    "                                                                  stratify=dataset.labels,\n",
    "                                                                 )\n",
    "\n",
    "    train_dataset = Subset(dataset, train_idx)\n",
    "    test_dataset = Subset(dataset, val_idx)\n",
    "\n",
    "    sampler = None\n",
    "    train_loader = DataLoader(train_dataset, shuffle=True, sampler=sampler, pin_memory=True, batch_size=200, num_workers=1)\n",
    "    test_loader = DataLoader(test_dataset, shuffle=False, pin_memory=True, batch_size=400, num_workers=1)\n",
    "\n",
    "    if uncertainty:\n",
    "        loss_func = edl_mse_loss\n",
    "    else:\n",
    "        loss_func = nn.BCELoss()\n",
    "    torch_device = \"cuda\"\n",
    "\n",
    "    seeds = seeds[:9]\n",
    "    accuracy_dict[dict_name] = []\n",
    "    accuracy_dict[dict_name + \"_final\"] = []\n",
    "    accuracy_dict[dict_name + \"_train\"] = []\n",
    "        \n",
    "    accs = []\n",
    "    final_accs = []\n",
    "    train_accs = []\n",
    "    for i in tqdm(range(0, 41)):\n",
    "        trainer_config = TrainerConfig()\n",
    "        probe = LinearProbeClassification(probe_class=len(label_to_id.keys()), device=\"cuda\", input_dim=5120,\n",
    "                                            logistic=logistic)\n",
    "        optimizer, scheduler = probe.configure_optimizers(trainer_config)\n",
    "        best_acc = 0\n",
    "        max_epoch = 50\n",
    "        verbosity = False\n",
    "        layer_num = i\n",
    "        print(\"-\" * 40 + f\"Layer {layer_num}\" + \"-\" * 40)\n",
    "        for epoch in range(1, max_epoch + 1):\n",
    "            if epoch == max_epoch:\n",
    "                verbosity = True\n",
    "            # Get the train results from training of each epoch\n",
    "            if uncertainty:\n",
    "                train_results = train(probe, torch_device, train_loader, optimizer, \n",
    "                                        epoch, loss_func=loss_func, verbose_interval=None,\n",
    "                                        verbose=verbosity, layer_num=layer_num, \n",
    "                                        return_raw_outputs=True, epoch_num=epoch, num_classes=len(label_to_id.keys()))\n",
    "                test_results = test(probe, torch_device, test_loader, loss_func=loss_func, \n",
    "                                    return_raw_outputs=True, verbose=verbosity, layer_num=layer_num,\n",
    "                                    scheduler=scheduler, epoch_num=epoch, num_classes=len(label_to_id.keys()))\n",
    "            else:\n",
    "                train_results = train(probe, torch_device, train_loader, optimizer, \n",
    "                                        epoch, loss_func=loss_func, verbose_interval=None,\n",
    "                                        verbose=verbosity, layer_num=layer_num,\n",
    "                                        return_raw_outputs=True,\n",
    "                                        one_hot=one_hot, num_classes=len(label_to_id.keys()))\n",
    "                test_results = test(probe, torch_device, test_loader, loss_func=loss_func, \n",
    "                                    return_raw_outputs=True, verbose=verbosity, layer_num=layer_num,\n",
    "                                    scheduler=scheduler,\n",
    "                                    one_hot=one_hot, num_classes=len(label_to_id.keys()))\n",
    "\n",
    "            if test_results[1] > best_acc:\n",
    "                best_acc = test_results[1]\n",
    "                torch.save(probe.state_dict(), f\"probe_checkpoints/reading_probe/{dict_name}_probe_at_layer_{layer_num}.pth\")\n",
    "        torch.save(probe.state_dict(), f\"probe_checkpoints/reading_probe/{dict_name}_probe_at_layer_{layer_num}_final.pth\")\n",
    "        \n",
    "        accs.append(best_acc)\n",
    "        final_accs.append(test_results[1])\n",
    "        train_accs.append(train_results[1])\n",
    "        cm = confusion_matrix(test_results[3], test_results[2])\n",
    "        cm_display = ConfusionMatrixDisplay(cm, display_labels=label_to_id.keys()).plot()\n",
    "        plt.show()\n",
    "\n",
    "        accuracy_dict[dict_name].append(accs)\n",
    "        accuracy_dict[dict_name + \"_final\"].append(final_accs)\n",
    "        accuracy_dict[dict_name + \"_train\"].append(train_accs)\n",
    "        \n",
    "        with open(\"probe_checkpoints/reading_probe_experiment.pkl\", \"wb\") as outfile:\n",
    "            pickle.dump(accuracy_dict, outfile)\n",
    "    del dataset, train_dataset, test_dataset, train_loader, test_loader\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc636c91-77a9-470c-911b-8dda701cb5ee",
   "metadata": {},
   "source": [
    "### Control Probe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6a9940-5e96-4af2-ba7d-6ea97bbf2500",
   "metadata": {},
   "outputs": [],
   "source": [
    "from probes import LinearProbeClassification, LinearProbeClassificationMixScaler\n",
    "import sklearn.model_selection\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "jump_socioeco = True\n",
    "\n",
    "new_prompt_format=True\n",
    "residual_stream=True\n",
    "uncertainty = False\n",
    "logistic = True\n",
    "augmented = False\n",
    "remove_last_ai_response = True\n",
    "include_inst = True\n",
    "one_hot = True\n",
    "\n",
    "label_to_id_age = {\"child\": 0,\n",
    "                   \"adolescent\": 1,\n",
    "                   \"adult\": 2,\n",
    "                   \"older adult\": 3,\n",
    "                  }\n",
    "\n",
    "label_to_id_gender = {\"male\": 0,\n",
    "                      \"female\": 1,\n",
    "                     }\n",
    "\n",
    "label_to_id_socioeconomic = {\"low\": 0,\n",
    "                             \"middle\": 1,\n",
    "                             \"high\": 2}\n",
    "\n",
    "label_to_id_neweducation = {\"someschool\": 0,\n",
    "                            \"highschool\": 1,\n",
    "                            \"collegemore\": 2}\n",
    "\n",
    "prompt_translator = {\"_age_\": \"age\",\n",
    "                     \"_gender_\": \"gender\",\n",
    "                     \"_socioeco_\": \"socioeconomic status\",\n",
    "                     \"_education_\": \"education level\",}\n",
    "\n",
    "openai_dataset = {\"_age_\": \"dataset/openai_age_1/\",\n",
    "                  \"_gender_\": \"dataset/openai_gender_1/\",\n",
    "                  \"_education_\": \"dataset/openai_education_1/\",\n",
    "                  \"_socioeco_\": \"dataset/openai_socioeconomic_1/\",}\n",
    "\n",
    "accuracy_dict = {}\n",
    "\n",
    "directories = [\"dataset/llama_age_1/\", \"dataset/llama_gender_1/\",\n",
    "               \"dataset/llama_socioeconomic_1/\", \"dataset/openai_education_1/\"]\n",
    "\n",
    "label_idfs = [\"_age_\", \"_gender_\", \"_socioeco_\", \"_education_\"]\n",
    "\n",
    "label_to_ids = [label_to_id_age, label_to_id_gender,\n",
    "                label_to_id_socioeconomic, label_to_id_neweducation]\n",
    "\n",
    "for directory, label_idf, label_to_id in zip(directories, label_idfs, label_to_ids):\n",
    "    # additional_dataset=[directory[:-1] + \"_additional/\"]\n",
    "    if label_idf == \"_education_\":\n",
    "        additional_dataset=[]\n",
    "    else:\n",
    "        additional_dataset=[directory[:-2] + \"_2/\", openai_dataset[label_idf]]\n",
    "    if label_idf == \"_gender_\":\n",
    "        additional_dataset += [\"dataset/openai_gender_2/\", \"dataset/openai_gender_3/\", \n",
    "                               \"dataset/openai_gender_4\",]\n",
    "    if label_idf == \"_education_\":\n",
    "        additional_dataset += [\"dataset/openai_education_2\", \"dataset/openai_education_3/\"]\n",
    "    if label_idf == \"_socioeco_\":\n",
    "        additional_dataset += [\"dataset/openai_socioeconomic_2/\", \"dataset/openai_socioeconomic_3/\"]\n",
    "    if label_idf == \"_age_\":\n",
    "        additional_dataset += [\"dataset/openai_age_2/\", \"dataset/openai_age_3/\"]\n",
    "        \n",
    "    dataset = TextDataset(directory, tokenizer, model, label_idf=label_idf, label_to_id=label_to_id,\n",
    "                          convert_to_llama2_format=True, additional_datas=additional_dataset, \n",
    "                          new_format=new_prompt_format, control_probe=True,\n",
    "                          residual_stream=residual_stream, if_augmented=augmented, \n",
    "                          remove_last_ai_response=remove_last_ai_response, include_inst=include_inst, k=1,\n",
    "                          one_hot=False, last_tok_pos=-1)\n",
    "    dict_name = label_idf.strip(\"_\")\n",
    "\n",
    "    train_size = int(0.8 * len(dataset))\n",
    "    test_size = len(dataset) - train_size\n",
    "    train_idx, val_idx = sklearn.model_selection.train_test_split(list(range(len(dataset))), \n",
    "                                                                  test_size=test_size,\n",
    "                                                                  train_size=train_size,\n",
    "                                                                  random_state=12345,\n",
    "                                                                  shuffle=True,\n",
    "                                                                  stratify=dataset.labels,\n",
    "                                                                 )\n",
    "\n",
    "    train_dataset = Subset(dataset, train_idx)\n",
    "    test_dataset = Subset(dataset, val_idx)\n",
    "\n",
    "    sampler = None\n",
    "    train_loader = DataLoader(train_dataset, shuffle=True, sampler=sampler, pin_memory=True, batch_size=200, num_workers=1)\n",
    "    test_loader = DataLoader(test_dataset, shuffle=False, pin_memory=True, batch_size=400, num_workers=1)\n",
    "\n",
    "    if uncertainty:\n",
    "        loss_func = edl_mse_loss\n",
    "    else:\n",
    "        loss_func = nn.BCELoss()\n",
    "    torch_device = \"cuda\"\n",
    "\n",
    "    seeds = seeds[:9]\n",
    "    accuracy_dict[dict_name] = []\n",
    "    accuracy_dict[dict_name + \"_final\"] = []\n",
    "    accuracy_dict[dict_name + \"_train\"] = []\n",
    "        \n",
    "    accs = []\n",
    "    final_accs = []\n",
    "    train_accs = []\n",
    "    for i in tqdm(range(0, 41)):\n",
    "        trainer_config = TrainerConfig()\n",
    "        probe = LinearProbeClassification(probe_class=len(label_to_id.keys()), device=\"cuda\", input_dim=5120,\n",
    "                                            logistic=logistic)\n",
    "        optimizer, scheduler = probe.configure_optimizers(trainer_config)\n",
    "        best_acc = 0\n",
    "        max_epoch = 50\n",
    "        verbosity = False\n",
    "        layer_num = i\n",
    "        print(\"-\" * 40 + f\"Layer {layer_num}\" + \"-\" * 40)\n",
    "        for epoch in range(1, max_epoch + 1):\n",
    "            if epoch == max_epoch:\n",
    "                verbosity = True\n",
    "            # Get the train results from training of each epoch\n",
    "            if uncertainty:\n",
    "                train_results = train(probe, torch_device, train_loader, optimizer, \n",
    "                                        epoch, loss_func=loss_func, verbose_interval=None,\n",
    "                                        verbose=verbosity, layer_num=layer_num, \n",
    "                                        return_raw_outputs=True, epoch_num=epoch, num_classes=len(label_to_id.keys()))\n",
    "                test_results = test(probe, torch_device, test_loader, loss_func=loss_func, \n",
    "                                    return_raw_outputs=True, verbose=verbosity, layer_num=layer_num,\n",
    "                                    scheduler=scheduler, epoch_num=epoch, num_classes=len(label_to_id.keys()))\n",
    "            else:\n",
    "                train_results = train(probe, torch_device, train_loader, optimizer, \n",
    "                                        epoch, loss_func=loss_func, verbose_interval=None,\n",
    "                                        verbose=verbosity, layer_num=layer_num,\n",
    "                                        return_raw_outputs=True,\n",
    "                                        one_hot=one_hot, num_classes=len(label_to_id.keys()))\n",
    "                test_results = test(probe, torch_device, test_loader, loss_func=loss_func, \n",
    "                                    return_raw_outputs=True, verbose=verbosity, layer_num=layer_num,\n",
    "                                    scheduler=scheduler,\n",
    "                                    one_hot=one_hot, num_classes=len(label_to_id.keys()))\n",
    "\n",
    "            if test_results[1] > best_acc:\n",
    "                best_acc = test_results[1]\n",
    "                torch.save(probe.state_dict(), f\"probe_checkpoints/controlling_probe/{dict_name}_probe_at_layer_{layer_num}.pth\")\n",
    "        torch.save(probe.state_dict(), f\"probe_checkpoints/controlling_probe/{dict_name}_probe_at_layer_{layer_num}_final.pth\")\n",
    "        \n",
    "        accs.append(best_acc)\n",
    "        final_accs.append(test_results[1])\n",
    "        train_accs.append(train_results[1])\n",
    "        cm = confusion_matrix(test_results[3], test_results[2])\n",
    "        cm_display = ConfusionMatrixDisplay(cm, display_labels=label_to_id.keys()).plot()\n",
    "        plt.show()\n",
    "\n",
    "        accuracy_dict[dict_name].append(accs)\n",
    "        accuracy_dict[dict_name + \"_final\"].append(final_accs)\n",
    "        accuracy_dict[dict_name + \"_train\"].append(train_accs)\n",
    "        \n",
    "        with open(\"probe_checkpoints/controlling_probe_experiment.pkl\", \"wb\") as outfile:\n",
    "            pickle.dump(accuracy_dict, outfile)\n",
    "    del dataset, train_dataset, test_dataset, train_loader, test_loader\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8487aec4-ef3f-423c-982d-547fcb475475",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
